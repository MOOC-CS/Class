#Practical Machine Learning - Data Science Specialization

## Overview
In this report we create a model based upon sensor data and apply it to some test data to predict whether or not an excercise was performed correctly.

Get the data

```
library(caret)
library(randomForest)

trainUrl <- "http://d396qusza40orc.cloudfront.net/predmachlearn/pml-training.csv"
testUrl <- "http://d396qusza40orc.cloudfront.net/predmachlearn/pml-testing.csv"
training <- read.csv(url(trainUrl), na.strings=c("NA","#DIV/0!",""))
testing <- read.csv(url(testUrl), na.strings=c("NA","#DIV/0!",""))
set.seed(12345)
```

## Looking at Cleaning the Data and splitting the data into training and test

```
qt_NA <- apply(training, 2, function(x) { sum(is.na(x)) })

training <- subset(training[, which(qt_NA == 0)], 
                     select=-c(X, user_name, new_window, num_window, raw_timestamp_part_1, raw_timestamp_part_2, cvtd_timestamp))
qt_NA <- apply(testing, 2, function(x) { sum(is.na(x)) })

testing <- subset(testing[, which(qt_NA == 0)], 
                     select=-c(X, user_name, new_window, num_window, raw_timestamp_part_1, raw_timestamp_part_2, cvtd_timestamp))

inTrain <- createDataPartition(y=training$classe, p=0.6, list=FALSE)
myTraining <- training[inTrain, ]; myTesting <- training[-inTrain, ]




```
## Random Forest Model
Using the Random Forrest ML we create a model using cross valudation with 5 subsets. 
```
mRF <- train(classe ~ ., data=training, method="rf", trControl=trainControl(method="cv", number=5))
```

This will run the model on the test set
```
predictRF <- predict(mRF, testing)
confusionMatrix(testing$classe, predictRF)$table
confusionMatrix(testing$classe, predictRF)$overall
```


Overall Statistics

           Accuracy : 0.9986          
             95% CI : (0.9975, 0.9993)
No Information Rate : 0.2845          
P-Value [Acc > NIR] : < 2.2e-16       

              Kappa : 0.9982          
Mcnemar's Test P-Value : NA

The test set was used to help predict the out of sample error rate. This is expected to be below 1%, or 100%-99.86%. 


I also tried decision trees, SVM, PCA, random forests. Random forests had the best sensitivity which is what is valued in the biomedical field. This data was cleaned and The statistics for the random forest can be seen above. One idea I also tried was to run random forrest, SVM, and Decision Tree on the data individually and then have the computer check if they all agree. If not go with the most common answer. This ensemble method ended up being slower and not better than the simple random forest.

